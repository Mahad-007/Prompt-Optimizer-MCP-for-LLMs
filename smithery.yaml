name: prompt-optimizer-mcp
description: A Model Context Protocol server for optimizing and scoring LLM prompts
version: 1.0.0

# Runtime configuration
runtime: python3.11

# Entry point
entrypoint: server.py

# Dependencies
dependencies:
  - mcp-server-fastmcp>=0.1.0

# Environment variables
environment:
  PYTHONPATH: .

# Build configuration
build:
  context: .
  dockerfile: Dockerfile
  args:
    PYTHON_VERSION: 3.11

# Resources
resources:
  cpu: 0.5
  memory: 512Mi

# Scaling
scaling:
  min_replicas: 1
  max_replicas: 3
  target_cpu_utilization: 70 